{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aNA1QzeXter9"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from fastai import *\n",
    "from fastai.vision import *\n",
    "import torch\n",
    "import os\n",
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "I1yePuLDPp1q"
   },
   "source": [
    "**data from https://www.kaggle.com/mloey1/ahcd1**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = Path('data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NKRpEDv-teux"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3360, 1024), (3360,), (1024,), 27, 0, 255.0)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_x = np.genfromtxt(data_path/'csvTestImages 3360x1024.csv', delimiter=',')\n",
    "test_y = np.genfromtxt(data_path/'csvTestLabel 3360x1.csv', delimiter=',')\n",
    "test_y = test_y.astype(int) - 1\n",
    "test_x = test_x.astype(float)\n",
    "\n",
    "\n",
    "test_x.shape, test_y.shape, test_x[0].shape, test_y.max(), test_y.min(), max(test_x.max(axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OGVOctF1BIZQ"
   },
   "outputs": [],
   "source": [
    "class ArabicMnist(Dataset):\n",
    "    def __init__(self, X, y=None):\n",
    "        super().__init__()\n",
    "        self.classes = np.unique(y)\n",
    "        self.c = len(np.unique(y))\n",
    "        self.X = X\n",
    "        if y is not None: self.y = y\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        image = self.X[i]\n",
    "        arr = (image - image.mean()) / image.std() # normalizes between -1 and +1\n",
    "        arr = (arr + 1) / 2 * 255 # moves it between 0 and 255\n",
    "        arr /= 255.0   ### WITH RANGE [0 ... 1]\n",
    "#         arr = np.clip(arr, 0, 255).astype(np.uint8),\n",
    "        arr3D = np.tile(arr[..., None], 3)\n",
    "#         arr3D = 256 - arr3D\n",
    "        arr3D = np.transpose(arr3D, (2, 1, 0))\n",
    "        new_tensor = torch.from_numpy(arr3D).float()\n",
    "        return (new_tensor, self.y[i])\n",
    "    \n",
    "    def __len__(self): return len(self.X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DkdnXSB4EqcZ"
   },
   "outputs": [],
   "source": [
    "test_x_reshaped = test_x.reshape([-1, 32, 32])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "C-HcoFdIFGIB",
    "outputId": "3d719921-46bf-4a8f-ae81-340f4147b5c6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3360, 32, 32), (3360,))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_x_reshaped.shape, test_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TyYczYXvu0Lr"
   },
   "outputs": [],
   "source": [
    "AM = ArabicMnist(test_x_reshaped[:2720], test_y[:2720])\n",
    "AMV = ArabicMnist(test_x_reshaped[2720:], test_y[2720:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Klut9hBp7ehr"
   },
   "outputs": [],
   "source": [
    "data = DataBunch.create(AM, AMV, bs=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[0.3682, 0.3682, 0.3682,  ..., 0.3682, 0.3682, 0.3682],\n",
       "          [0.3682, 0.3682, 0.3682,  ..., 0.3682, 0.3682, 0.3682],\n",
       "          [0.3682, 0.3682, 0.3682,  ..., 0.3682, 0.3682, 0.3682],\n",
       "          ...,\n",
       "          [0.3682, 0.3682, 0.3682,  ..., 0.3682, 0.3682, 0.3682],\n",
       "          [0.3682, 0.3682, 0.3682,  ..., 0.3682, 0.3682, 0.3682],\n",
       "          [0.3682, 0.3682, 0.3682,  ..., 0.3682, 0.3682, 0.3682]],\n",
       " \n",
       "         [[0.3682, 0.3682, 0.3682,  ..., 0.3682, 0.3682, 0.3682],\n",
       "          [0.3682, 0.3682, 0.3682,  ..., 0.3682, 0.3682, 0.3682],\n",
       "          [0.3682, 0.3682, 0.3682,  ..., 0.3682, 0.3682, 0.3682],\n",
       "          ...,\n",
       "          [0.3682, 0.3682, 0.3682,  ..., 0.3682, 0.3682, 0.3682],\n",
       "          [0.3682, 0.3682, 0.3682,  ..., 0.3682, 0.3682, 0.3682],\n",
       "          [0.3682, 0.3682, 0.3682,  ..., 0.3682, 0.3682, 0.3682]],\n",
       " \n",
       "         [[0.3682, 0.3682, 0.3682,  ..., 0.3682, 0.3682, 0.3682],\n",
       "          [0.3682, 0.3682, 0.3682,  ..., 0.3682, 0.3682, 0.3682],\n",
       "          [0.3682, 0.3682, 0.3682,  ..., 0.3682, 0.3682, 0.3682],\n",
       "          ...,\n",
       "          [0.3682, 0.3682, 0.3682,  ..., 0.3682, 0.3682, 0.3682],\n",
       "          [0.3682, 0.3682, 0.3682,  ..., 0.3682, 0.3682, 0.3682],\n",
       "          [0.3682, 0.3682, 0.3682,  ..., 0.3682, 0.3682, 0.3682]]]), 0)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img1 = data.train_ds[0]\n",
    "img1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fea3f70f6d8>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(np.transpose(img1[0], (2, 1, 0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xYhO0iIl7el4"
   },
   "outputs": [],
   "source": [
    "learn = create_cnn(data, models.resnet18, metrics=error_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time: 00:30\n",
      "epoch  train_loss  valid_loss  error_rate\n",
      "1      -0.050481   -0.087398   0.951563    (00:10)\n",
      "2      0.023616    -0.001692   0.971875    (00:09)\n",
      "3      0.063470    -0.065271   0.954687    (00:09)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# %%debug\n",
    "learn.fit(3, 1e-9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ArabicMnist(Dataset):\n",
    "    def __init__(self, X, y=None):\n",
    "        super().__init__()\n",
    "        self.classes = np.unique(y)\n",
    "        self.c = len(np.unique(y))\n",
    "        self.X = X\n",
    "        if y is not None: self.y = y\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        image = self.X[i]\n",
    "        arr = (image - image.mean()) / image.std() # normalizes between -1 and +1\n",
    "        arr = (arr + 1) / 2 * 255 # moves it between 0 and 255\n",
    "#         arr /= 255.0  ## WITH RANGE [0, 255]\n",
    "#         arr = np.clip(arr, 0, 255).astype(np.uint8),\n",
    "        arr3D = np.tile(arr[..., None], 3)\n",
    "#         arr3D = 256 - arr3D\n",
    "        arr3D = np.transpose(arr3D, (2, 1, 0))\n",
    "        new_tensor = torch.from_numpy(arr3D).float()\n",
    "        return (new_tensor, self.y[i])\n",
    "    \n",
    "    def __len__(self): return len(self.X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "AM = ArabicMnist(test_x_reshaped[:2720], test_y[:2720])\n",
    "AMV = ArabicMnist(test_x_reshaped[2720:], test_y[2720:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = DataBunch.create(AM, AMV, bs=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = create_cnn(data, models.resnet18, metrics=error_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time: 00:29\n",
      "epoch  train_loss  valid_loss  error_rate\n",
      "1      0.005595    0.063722    0.970312    (00:09)\n",
      "2      0.052280    -0.058503   0.956250    (00:09)\n",
      "3      -0.036031   -0.035565   0.960938    (00:09)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# %%debug\n",
    "learn.fit(3, 1e-9)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "ARCHAR.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
